Control ID	Control	Risk ID	Description	Databricks Shared Responsibility	Databricks Product Reference	Databricks Documentation (AWS)	Databricks Documentation (Azure)	Databricks Documentation (GCP)	DASF Revision	Security Control Type	AI System Component Step	Security Analysis Tool (SAT)	AI System Novelty	MITRE ATLAS as of Q3 2024	MITRE ATTACK as of Q3 2024	OWASP LLM Top 10 2025	OWASP ML Top 10 v0.3	ISO 42001:2023 Controls Objectives and Controls (Annex A)	ISO 27001:2022 Information Security Control Reference (Annex A)	NIST - 800- 53 - Rev 5	HITRUST	ENISA’s Securing ML Algorithms	EU AI ACT
DASF 1	DASF 1: SSO with IdP and MFA	Raw data 1.1, Data Prep 2.1, Data Prep 2.2, Data Prep 2.3, Data Prep 2.4, Datasets 3.1, Evaluation 6.1, Model 7.1, Model 7.2, Model Management 8.2, Model Management 8.4, Model Serving - Inference requests 9.1, Model Serving - Inference requests 9.2, Model Serving - Inference requests 9.5, Model Serving - Inference requests 9.6, Model Serving - Inference requests 9.7, Model Serving - Inference requests 9.9, Model Serving - Inference requests 9.10,Model Serving — Inference requests 9.11, Model Serving — Inference requests 9.12 ,Model Serving - Inference response 10.3, Model Serving - Inference response 10.4, Platform 12.7: Initial Access	Implementing single sign-on with an identity provider’s (IdP) multi-factor authentication is critical for secure authentication. It adds an extra layer of security, ensuring that only authorized users access the Databricks Platform.	Databricks — Configuration	Customer configured, Databricks enforced	https://docs.databricks.com/en/admin/account-settings-e2/single-sign-on/index.html#unified-login	https://learn.microsoft.com/en-us/azure/databricks/security/auth-authz/#sso	https://docs.gcp.databricks.com/en/security/auth-authz/index.html#single-sign-on	DASF v 1.0	Access and Authentication	Operations and Platform 	IA-1	Traditional Control/Capability	no mapping	M1036 Account Use Policies M1032 Multi-factor Authentication M1027 Password Policies	LLM01.1: Prompt Injection LLM02.1: Insecure Output Handling LLM03.CEV.5: Training Data Poisoning LLM06.3: Sensitive Information Disclosure LLM07.4,5, 6: Insecure Plugin Design LLM08.5, 7: Excessive Agency	ML02:2023 Data Poisoning Attack ML03:2023 Model Inversion Attack ML04:2023 Membership Inference Attack ML05:2023 Model Theft ML08:2023 Model Skewing ML09:2023 Output Integrity Attack ML10:2023 Model Poisoning	no mapping	A.5.16 Identity management A.8.5 Secure authentication	IA-2:Identification and Authentication (Organizational Users),  IA-5:Authenticator Management,  IA-12:Identity Proofing,  SC-12:Cryptographic Key Establishment and Management, SC-23:Session Authenticity 	Access to the AI system -> Restrict access to data used for AI Access to the AI system ->  Restrict access to AI models Access to the AI system -> Restrict access to the AI engineering environment and AI code	Apply a RBAC Model, Respecting the Least Privileged Principle. Ensure ML Applications Comply with Identity Management, Authentication, and Access Control Policies.	no mapping
DASF 2	DASF 2: Sync users and groups 	Raw data 1.1, Data Prep 2.1, Data Prep 2.2, Data Prep 2.3, Data Prep 2.4, Datasets 3.1, Evaluation 6.1, Model 7.2, Model Management 8.2, Model Management 8.4, Model Serving - Inference requests 9.1, Model Serving - Inference requests 9.2, Model Serving - Inference requests 9.5, Model Serving - Inference requests 9.6, Model Serving - Inference requests 9.7, Model Serving - Inference requests 9.9, Model Serving - Inference requests 9.10, Model Serving — Inference requests 9.11,  Model Serving — Inference requests 9.12, Model Serving - Inference response 10.3, Model Serving - Inference response 10.4,Platform 12.7: Initial Access	Synchronizing users and groups from your identity provider (IdP) with Databricks using the SCIM standard facilitates consistent and automated user provisioning for enhancing security.	Databricks — Configuration	Customer configured, Databricks enforced	https://docs.databricks.com/en/administration-guide/users-groups/scim/index.html	https://learn.microsoft.com/en-us/azure/databricks/administration-guide/users-groups/scim/	https://docs.gcp.databricks.com/en/administration-guide/users-groups/scim/index.html	DASF v 1.0	Access and Authentication	Operations and Platform 	IA-2	Traditional Control/Capability	no mapping	M1015 Active Directory Configuration M1018 User Account Management	LLM01.1: Prompt Injection LLM02.1: Insecure Output Handling LLM03.CEV.5: Training Data Poisoning LLM06.3: Sensitive Information Disclosure LLM07.4,5, 6: Insecure Plugin Design LLM08.5, 7: Excessive Agency	ML02:2023 Data Poisoning Attack ML03:2023 Model Inversion Attack ML04:2023 Membership Inference Attack ML05:2023 Model Theft ML08:2023 Model Skewing ML09:2023 Output Integrity Attack ML10:2023 Model Poisoning	no mapping	A.5.18 Access rights	AC-2:Account Management,  IA-4:Identifier Management,  CM-2:Baseline Configuration	Access to the AI system -> Restrict access to data used for AI Access to the AI system ->  Restrict access to AI models 	Apply a RBAC Model, Respecting the Least Privileged Principle. Ensure ML Applications Comply with Identity Management, Authentication, and Access Control Policies.	no mapping
DASF 3	DASF 3: Restrict access using IP access lists	Raw data 1.1, Data Prep 2.1, Data Prep 2.2, Data Prep 2.3, Data Prep 2.4, Datasets 3.1, Evaluation 6.1, Model 7.2, Model Management 8.2, Model Management 8.4, Model Serving - Inference requests 9.1, Model Serving - Inference requests 9.2, Model Serving - Inference requests 9.5, Model Serving - Inference requests 9.6, Model Serving - Inference requests 9.7, Model Serving - Inference requests 9.9, Model Serving - Inference requests 9.10,Model Serving — Inference requests 9.11,  Model Serving — Inference requests 9.12, Model Serving - Inference response 10.3, Model Serving - Inference response 10.4,Platform 12.7: Initial Access	Configure IP access lists to restrict authentication to Databricks from specific IP ranges, such as VPNs or office networks, and strengthen network security by preventing unauthorized access from untrusted locations.   Secure Egress Gateway (SEG) is a component of Databricks Platform Security that allows an administrator to implement policies that restrict access to internal or external endpoints. Currently, SEG only applies to Serverless runtimes.	Databricks — Configuration	Customer configured, Databricks enforced	https://docs.databricks.com/en/security/network/ip-access-list.html	https://learn.microsoft.com/en-us/azure/databricks/security/network/front-end/ip-access-list	https://docs.gcp.databricks.com/en/security/network/front-end/ip-access-list.html	DASF v 1.0	Access and Authentication	Operations and Platform 	NS-5	Traditional Control/Capability	no mapping	M1035  Limit Access to Resource Over Network	LLM01: Prompt Injection LLM03.4, 5: Training Data Poisoning LLM06.3: Sensitive Information Disclosure LLM10.2: Model Theft	ML02:2023 Data Poisoning Attack	no mapping	A.8.20 Networks Security A.8.21 Security of network services A.8.22 Segregation of networks	SC-7:Boundary Protection,  AC-3:Access Enforcement	no mapping	no mapping	no mapping
DASF 4	DASF 4: Restrict access using private link 	Raw data 1.1, Data prep 2.1, Data Prep 2.2, Data Prep 2.3, Data Prep 2.4, Datasets 3.1, Evaluation 6.1, Model 7.2, Model Management 8.2, Model Management 8.4, Model Serving - Inference requests 9.1, Model Serving - Inference requests 9.2, Model Serving - Inference requests 9.5, Model Serving - Inference requests 9.6, Model Serving - Inference requests 9.7, Model Serving - Inference requests 9.9, Model Serving - Inference requests 9.10, Model Serving — Inference requests 9.11, Model Serving - Inference response 10.3, Model Serving - Inference response 10.4,Platform 12.7: Initial Access	Use AWS PrivateLink, Azure Private Link or GCP Private Service Connect to create a private network route between the customer and the Databricks control plane or the control plane and the customer’s compute plane environments to enhance data security by avoiding public internet exposure.	Databricks — Configuration	Customer configured, Databricks enforced	https://docs.databricks.com/en/administration-guide/cloud-configurations/aws/privatelink.html	https://learn.microsoft.com/en-us/azure/databricks/security/network/classic/private-link	https://docs.gcp.databricks.com/en/security/network/classic/private-service-connect.html	DASF v 1.0	Access and Authentication	Operations and Platform 	NS-3	Traditional Control/Capability	no mapping	M1035  Limit Access to Resource Over Network M1030  Network Segmentation	LLM01: Prompt Injection LLM03.4, 5: Training Data Poisoning LLM06.3: Sensitive Information Disclosure LLM10.2: Model Theft	ML02:2023 Data Poisoning Attack	no mapping	A.8.20 Networks Security A.8.21 Security of network services A.8.22 Segregation of networks	SC-3:Security Function Isolation, SC-7:Boundary Protection 	no mapping	no mapping	no mapping
DASF 5	DASF 5: Control access to data and other objects	Raw data 1.1, Raw data 1.4, Raw data 1.11,  Model Serving — Inference requests 9.12, Data Prep 2.1, Datasets 3.1, Datasets 3.2, Datasets 3.3, Governance 4.1, Evaluation 6.1, Model 7.1, Model 7.2, Model Management 8.1, Model Management 8.2, Model Management 8.3, Model Management 8.4, Model Serving - Inference requests 9.1, Model Serving - Inference requests 9.2, Model Serving - Inference requests 9.5, Model Serving - Inference requests 9.6, Model Serving - Inference requests 9.7, Model Serving - Inference requests 9.9, Model Serving - Inference requests 9.10, Model Serving — Inference requests 9.11,  Model Serving — Inference requests 9.12,Model Serving - Inference response 10.3, Model Serving - Inference response 10.4, Platform 12.7: Initial Access	Implementing Unity Catalog for unified permissions management and assets simplifies access control and enhances security.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/data-governance/unity-catalog/manage-privileges/privileges.html	https://learn.microsoft.com/en-us/azure/databricks/sql/language-manual/sql-ref-privileges	https://docs.gcp.databricks.com/en/data-governance/unity-catalog/manage-privileges/privileges.html	DASF v 1.0	Access and Authentication	Catalog and governance, Model management	GOV-16, GOV-20	Traditional Control/Capability	AML.M0005 Control Access to ML Models and Data at Rest	M1029 Remote Data Storage M1022  Restrict File and Directory Permissions 	LLM01.1: Prompt Injection LLM02.1: Insecure Output Handling LLM03.CEV.5: Training Data Poisoning LLM06.3: Sensitive Information Disclosure LLM07.4,5, 6: Insecure Plugin Design LLM08.5, 7: Excessive Agency LLM10.1,4: Model Theft	ML02:2023 Data Poisoning Attack ML03:2023 Model Inversion Attack ML04:2023 Membership Inference Attack ML05:2023 Model Theft ML08:2023 Model Skewing ML09:2023 Output Integrity Attack ML10:2023 Model Poisoning	no mapping	A.5.15 Access control A.8.2 Privileged access rights A.8.3 Information access restriction A.8.4 Access to source code	AC-1:Policy and Procedures,  AC-2:Account Management,  AC-3:Access Enforcement,  AC-6:Least Privilege,  AC-17:Remote Access,  AC-20:Use of External Systems,  SC:System and Communications Protection Family,  IA:Identification and Authentication Family	AI security governance -> Humans can intervene if needed Access to the AI system -> Restrict access to data used for AI 	Apply a RBAC model, respecting the least privileged principle. Ensure ML applications comply with identity management, authentication, and access control policies. Ensure ML applications comply with data security requirements. Control all data used by the ML model. Ensure appropriate protection is deployed for test environments. Reduce the available information about the model. Reduce the information given by the model. Use federated learning to minimize the risk of data breaches.	Article 5.4 Prohibited AI Practices Article 5.1 Prohibited AI Practices
DASF 6	DASF 6: Classify data	Raw data 1.2,  Model Serving — Inference requests 9.13	Tags are attributes containing keys and optional values that you can apply to different securable objects in Unity Catalog. Organizing securable objects with tags in Unity Catalog aids in efficient data management, data discovery and classification, essential for handling large datasets.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/data-governance/unity-catalog/tags.html	https://learn.microsoft.com/en-us/azure/databricks/data-governance/unity-catalog/tags	https://docs.gcp.databricks.com/en/data-governance/unity-catalog/tags.html	DASF v 1.0	Data Governance and Quality	Data preparation, Data sets	Features available to implement control and manually verify	Traditional Control/Capability	no mapping	M1057 Data Loss Prevention	LLM03.2, 4, 5: Training Data Poisoning LLM05.1: Supply Chain Vulnerabilities,  LLM06.3: Sensitive Information Disclosure	ML02:2023 Data Poisoning Attack	A.7.4 Quality of data for AI systems	A.5.12 Classification of information	RA-2:Security Categorization,  AC-3:Access Enforcement,  MP:Media Protection Family,  PT:Personally Identifiable Information Processing and Transparency Family	no mapping	Control All Data Used by the ML Model. Ensure ML Applications Comply with Data Security Requirements. Ensure Appropriate Protection Is Deployed for Test Environments.	no mapping
DASF 7	DASF 7: Enforce data quality checks on batch and streaming datasets 	Raw data 1.3, Raw data 1.9, Raw data 1.11,  Data Prep 2.1, Datasets 3.1, Governance 4.1, Evaluation 6.1	Databricks Delta Live Tables (DLT) simplifies ETL development with declarative pipelines that integrate quality control checks and performance monitoring.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/delta-live-tables/expectations.html	https://learn.microsoft.com/en-us/azure/databricks/delta-live-tables/expectations	https://docs.gcp.databricks.com/en/delta-live-tables/expectations.html	DASF v 1.0	Data Governance and Quality	Data preparation	Customer validated	Traditional Control/Capability	AML.M0007 Sanitize Training Data	no mapping	LLM03.2, 4, 5: Training Data Poisoning LLM05.1: Supply Chain Vulnerabilities,  LLM06.3: Sensitive Information Disclosure	no mapping	A.7.4 Quality of data for AI systems A.7.6 Data preparation	no mapping	SI-10:Information Input Validation,  SI-11:Error Handling,  SI-18:Personally Identifiable Information Quality Operations,  AU-6:Audit Record Review, Analysis, and Reporting,  CM:Configuration Management Family	Filtering and sanitizing AI data, inputs, and outputs ->  Dataset sanitization	Control All Data Used by the ML Model. Use Methods to Clean the Training Dataset from Suspicious Samples.	
DASF 8	DASF 8: Encrypt data at rest 	Raw data 1.4, Datasets 3.2, Datasets 3.3	Databricks supports customer-managed encryption keys to strengthen data at rest protection and greater access control.	Databricks — Configuration	Customer configured, Databricks enforced	https://docs.databricks.com/en/security/keys/customer-managed-keys.html	https://learn.microsoft.com/en-us/azure/databricks/security/keys/customer-managed-keys	https://docs.gcp.databricks.com/en/security/keys/customer-managed-keys.html	DASF v 1.0	Data and model security	Model management, ML Operations	DP-4, DP-2	Traditional Control/Capability	AML.M0012 Encrypt Sensitive Information	M1041 Encrypt Sensitive Information	LLM03.2, 4, 5: Training Data Poisoning LLM05.1: Supply Chain Vulnerabilities,  LLM06.3: Sensitive Information Disclosure LLM10: Model Theft	ML02:2023 Data Poisoning Attack ML03:2023 Model Inversion Attack ML04:2023 Membership Inference Attack ML05:2023 Model Theft	no mapping	A.8.24 Use of cryptography	SC-8:Transmission Confidentiality and Integrity,  SC-12:Cryptographic Key Establishment and Management, SC-28:Protection of Information at Rest,  AU-9:Protection of Audit Information,  CP-9:System Backup,  MP-4:Media Storage,  SI-7:Software, Firmware, and Information Integrity 	no mapping	Ensure ML Applications Comply with Data Security Requirements. Control All Data Used by the ML Model.	Article 5.4 Prohibited AI Practices
DASF 9	DASF 9: Encrypt data in transit	Raw data 1.4, Datasets 3.2, Datasets 3.3	Databricks supports TLS 1.2+ encryption to protect customer data during transit. This applies to data transfer between the customer and the Databricks control plane and within the compute plane. Customers can also secure inter-cluster communications within the compute plane per their security requirements.	Databricks — Out-of-the-box	Databricks Managed	https://www.databricks.com/legal/security-addendum	https://www.databricks.com/legal/security-addendum	https://www.databricks.com/legal/security-addendum	DASF v 1.0	Data and model security	Model Serving: Inference requests, Model Serving: Inference responses	Out of the box	Traditional Control/Capability	AML.M0012 Encrypt Sensitive Information	M1041 Encrypt Sensitive Information M1020 SSL/TLS Inspection	LLM03.2, 4, 5: Training Data Poisoning LLM05.1: Supply Chain Vulnerabilities,  LLM06.3: Sensitive Information Disclosure LLM10: Model Theft	ML02:2023 Data Poisoning Attack	no mapping	A.8.24 Use of cryptography	SC-7:Boundary Protection, SC-8:Transmission Confidentiality and Integrity,  AC-17:Remote Access,  AC-18:Wireless Access	Encryption -> Encrypt traffic to and from the AI model	Ensure ML Applications Comply with Data Security Requirements. Control All Data Used by the ML Model. Use Federated Learning to Minimize Risk of Data Breaches.	Article 5.4 Prohibited AI Practices
DASF 10	DASF 10: Version data 	Raw data 1.5, Raw data 1.7	Store data in a lakehouse architecture using Delta tables. Delta tables can be versioned to revert any user or malicious actor poisoning of data. Data can be stored in a lakehouse architecture in the customer’s cloud account. Both raw data and feature tables are stored as Delta tables with access controls to determine who can read and modify them. Data lineage with UC helps track and audit changes and the origin of ML data sources. Each operation that modifies a Delta Lake table creates a new table version. User actions are tracked and audited, and lineage of transformations is available all in the same platform. You can use history information to audit operations, roll back a table or query a table at a specific point in time using time travel.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/delta/index.html	https://learn.microsoft.com/en-us/azure/databricks/delta/	https://docs.gcp.databricks.com/en/delta/index.html	DASF v 1.0	Data Governance and Quality	Raw data, Data sets	Out of the box	Traditional Control/Capability	no mapping	M1053 Data Backup	LLM03.2, 4, 5: Training Data Poisoning LLM05.1: Supply Chain Vulnerabilities,  LLM06.3: Sensitive Information Disclosure	no mapping	A.4.3 Data resources A.7.2 Data for development and enhancement of AI system	no mapping	CM-2:Baseline Configuration,  CM-8:System Component Inventory,  SI-7:Software, Firmware, and Information Integrity,  SR-4:Provenance,  SR-11:Component Authenticity 	Supply chain ->  Verification of origin and integrity of AI assets	Implement Processes to Maintain Security Levels of ML Components Over Time. Apply a RBAC Model, Respecting the Least Privileged Principle". Define and Monitor Indicators for Proper Functioning of the Model. Ensure ML Projects Follow the Global Process for Integrating Security into Projects.	no mapping
DASF 11	DASF 11: Capture and view data lineage	Raw data 1.6, Raw data 1.11, Data Prep 2.1, Datasets 3.1, Governance 4.1, Evaluation 6.1, Model Serving — Inference requests 9.13	Unity Catalog tracks and visualizes real-time data lineage across all languages to the column level, providing a traceable history of an object from notebooks, workflows, models and dashboards. This enhances transparency and compliance, with accessibility provided through the Catalog Explorer.	Databricks — Out-of-the-box	Databricks Managed	https://docs.databricks.com/en/data-governance/unity-catalog/data-lineage.html	https://learn.microsoft.com/en-us/azure/databricks/data-governance/unity-catalog/data-lineage	https://docs.gcp.databricks.com/en/data-governance/unity-catalog/data-lineage.html	DASF v 1.0	Data Governance and Quality	Raw data, Data sets	GOV-16	Traditional Control/Capability	no mapping	no mapping	LLM03.2, 4, 5: Training Data Poisoning LLM05.1, 5: Supply Chain Vulnerabilities,  LLM06.3: Sensitive Information Disclosure	no mapping	A.4.3 Data resources A.7.3 Acquisition of data	no mapping	AU-2:Event Logging,  AU-3:Content of Audit Records,  AU-12:Audit Record Generation,  CM-8:System Component Inventory,  CM-12:Information Location,  AC-4:Information Flow Enforcement,  SA-8:Security and Privacy Engineering Principles	Supply chain ->  Verification of origin and integrity of AI assets Documenting and inventorying AI systems -> Maintain a catalog of trusted data sources for AI Documenting and inventorying AI systems -> AI data and data supply inventory 	Control All Data Used by the ML Model. Ensure Reliable Sources Are Used. Use Methods to Clean the Training Dataset from Suspicious Samples. Implement Processes to Maintain Security Levels of ML Components Over Time.	no mapping
DASF 12	DASF 12: Delete records from datasets	Raw data 1.8	Data governance in Delta Lake, the lakehouse storage layer, utilizes its atomicity, consistency, isolation, durability (ACID) properties for effective data management. This includes the capability to remove data based on specific predicates from a Delta Table, including the complete removal of data’s history, supporting compliance with regulations like GDPR and CCPA.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/delta/tutorial.html#delete-from-a-table	https://learn.microsoft.com/en-us/azure/databricks/delta/tutorial#--delete-from-a-table	https://docs.gcp.databricks.com/en/delta/tutorial.html#delete-from-a-table	DASF v 1.0	Data Governance and Quality	Catalog and governance, raw data, data sets	Out of the box	Traditional Control/Capability	no mapping	no mapping	no mapping 	no mapping	A.2.3 Alignment with other organizational policies A.3.2 AI roles and responsibilities A.7.2 Data for development and enhancement of AI system A.9.3 Objectives for responsible use of AI system	A.5.34 Privacy and protection of personal identifiable information (PII) A.8.10 Information deletion	SI-7:Software, Firmware, and Information Integrity, SI-18:Personally Identifiable Information Quality Operations,  SI-19:De-identification,  AU-2:Event Logging,  AU-6:Audit Record Review, Analysis, and Reporting,  RA-7:Risk Response	AI legal and compliance -> ID and evaluate compliance & legal obligations for AI system development and deployment AI legal and compliance ->  ID and evaluate any constraints on data used for AI 	Use Methods to Clean the Training Dataset From Suspicious Samples. Control All Data Used by the ML Model. Ensure ML Applications Comply with Data Security Requirements.	no mapping
DASF 13	DASF 13: Use near real-time data 	Raw data 1.9	Use Databricks for near real-time data ingestion, processing, machine learning, and AI for streaming data.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/structured-streaming/index.html	https://learn.microsoft.com/en-us/azure/databricks/structured-streaming/	https://docs.gcp.databricks.com/en/structured-streaming/index.html	DASF v 1.0	Data Governance and Quality	ML Platform	Out of the box	Traditional Control/Capability	no mapping	no mapping	LLM03.*, CEV.5: Training Data Poisoning LLM05.1, 5: Supply Chain Vulnerabilities	ML08:2023 Model Skewing	A.7.2 Data for development and enhancement of AI system	no mapping	SI-4:System Monitoring,  SI-7:Software, Firmware, and Information Integrity,  RA-3:Risk Assessment,  RA-7:Risk Response	no mapping	Ensure That the Model is Sufficiently Resilient to the Environment in Which it Will Operate. Implement Processes to Maintain Security Levels of ML Components Over Time.	no mapping
DASF 14	DASF 14: Audit actions performed on datasets 	Raw data 1.10, Datasets 3.1	Databricks auditing, enhanced by Unity Catalog’s events, delivers fine-grained visibility into data access and user activities. This is vital for robust data governance and security, especially in regulated industries. It enables organizations to proactively identify and manage overentitled users, enhancing data security and ensuring compliance.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/data-governance/unity-catalog/audit.html	https://learn.microsoft.com/en-us/azure/databricks/data-governance/unity-catalog/audit	https://docs.gcp.databricks.com/en/data-governance/unity-catalog/audit.html	DASF v 1.0	Data Governance and Quality	All	GOV-3, GOV-34	Traditional Control/Capability	no mapping	no mapping	LLM05.5, 7: Supply Chain Vulnerabilities	ML02:2023 Data Poisoning Attack ML08:2023 Model Skewing	A.6.2.8 AI system recording of event logs	A.8.15 Logging	AU-2:Event Logging,  AU-3:Content of Audit Records,  AU-6:Audit Record Review, Analysis, and Reporting,  AU-9:Protection of Audit Information	AI system logging and monitoring -> Monitoring for data, models, and configs for suspicious changes  	Apply a RBAC Model, Respecting the Least Privileged Principle. Ensure ML Applications Comply with Data Security Requirements. Implement Processes to Maintain Security Levels of ML Components Over Time.	Article 12.3 Record Keeping
DASF 15	DASF 15: Explore datasets and identify problems 	Data Prep 2.1	Iteratively explore, share and prep data for the machine learning lifecycle by creating reproducible, editable and shareable datasets, tables and visualizations. Within Databricks this EDA process can be accelerated with Mosaic AI AutoML. AutoML not only generates baseline models given a dataset, but also provides the underlying model training code in the form of a Python notebook. Notably for EDA, AutoML calculates summary statistics on the provided dataset, creating a notebook for the data scientist to review and adapt.	Databricks — Implementation	Customer-managed	https://docs.databricks.com/en/exploratory-data-analysis/index.html	https://learn.microsoft.com/en-us/azure/databricks/exploratory-data-analysis/	https://docs.gcp.databricks.com/en/exploratory-data-analysis/index.html	DASF v 1.0	Data Governance and Quality	Catalog and Governance, Data preparation, ML algorithm	Features available to implement control and manually verify	Novel AI control/capability	AML.M0007 Sanitize Training Data	no mapping	LLM03.5: Training Data Poisoning LLM05.7: Supply Chain Vulnerabilities	ML02:2023 Data Poisoning Attack	A.7.4 Quality of data for AI systems A.7.6 Data preparation	no mapping	RA-3:Risk Assessment, RA-5:Vulnerability Monitoring and Scanning,  SI-7:Software, Firmware, and Information Integrity	Filtering and sanitizing AI data, inputs, and outputs ->  Dataset sanitization	Control All Data Used by the ML Model. Use Methods to Clean the Training Dataset from Suspicious Samples. Ensure Reliable Sources Are Used.	no mapping
DASF 16	DASF 16: Secure model features 	Data Prep 2.1, Data Prep 2.2, Datasets 3.1, Governance 4.1, Algorithms 5.2, Model Serving - Inference requests 9.10	Databricks Feature Store is a centralized repository that enables data scientists to find and share features and also ensures that the same code used to compute the feature values is used for model training and inference. Unity Catalog’s capabilities, such as security, lineage, table history, tagging and cross-workspace access, are automatically available to the feature table to reduce the risk of malicious actors manipulating the features that feed into ML training.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/machine-learning/feature-store/index.html	https://learn.microsoft.com/en-us/azure/databricks/machine-learning/feature-store/	https://docs.gcp.databricks.com/en/machine-learning/feature-store/index.html	DASF v 1.0	Access and Authentication	Raw data, Data sets	GOV-16	Novel AI control/capability	no mapping	no mapping	no mapping	no mapping	no mapping	A.8.3 Information access restriction A.8.2 Privileged access rights	SC-3:Security Function Isolation,  SC-8:Transmission Confidentiality and Integrity,  SC-28:Protection of Information at Rest,  SI-4:System Monitoring,  SI-7:Software, Firmware, and Information Integrity,  SI-10:Information Input Validation	Access to the AI system -> Restrict access to data used for AI	no mapping	Article 15.5 Accuracy, Robustness, and Cybersecurity  Article 15.1 Accuracy, Robustness, and Cybersecurity
DASF 17	DASF 17: Track and reproduce the training data used for ML model training 	Raw data 1.11, Data Prep 2.4, Datasets 3.1, Governance 4.1, Algorithms 5.2, Model Serving — Inference requests 9.11	MLflow with Delta Lake tracks the training data used for ML model training. It also enables the identification of specific ML models and runs derived from particular datasets for regulatory and auditable attribution.	Databricks — Configuration	Customer configured, Databricks enforced	https://docs.databricks.com/en/mlflow/tracking-ex-delta.html	https://learn.microsoft.com/en-us/azure/databricks/mlflow/tracking-ex-delta	https://docs.gcp.databricks.com/en/mlflow/tracking-ex-delta.html	DASF v 1.0	Data Governance and Quality	Data sets, ML algorithm, Model build	Out of the box	Novel AI control/capability	no mapping	no mapping	no mapping	ML02:2023 Data Poisoning Attack ML07:2023 Transfer Learning Attack	A.4.3 Data resources A.7 Data for AI systems A.7.2 Data for development and enhancement of AI system A.7.3 Acquisition of data A.7.4 Quality of data for AI systems A.7.5 Data provenance	no mapping	no mapping	Documenting and inventorying AI systems -> Maintain a catalog of trusted data sources for AI Documenting and inventorying AI systems -> AI data and data supply inventory 	Control All Data Used by the ML Model. Ensure Reliable Sources are Used. Ensure ML Applications Comply with Data Security Requirements. Use Methods to Clean the Training Dataset from Suspicious Samples. Apply Documentation Requirements to Artificial Intelligence Projects.	Article 72 Post-market monitoring
DASF 18	DASF 18: Govern model assets 	Governance 4.1	With Unity Catalog, organizations can implement a unified governance framework for their structured and unstructured data, machine learning models, notebooks, features, functions, and files, enhancing security and compliance across clouds and platforms. Maintain an updated inventory of high-impact AI use cases, including details on purpose, benefits, risks, and risk management practices.	Databricks — Configuration	Customer configured, Databricks enforced	https://docs.databricks.com/en/machine-learning/index.html#machine-learning-on-databricks	https://learn.microsoft.com/en-us/azure/databricks/machine-learning/#machine-learning-on-databricks	https://docs.gcp.databricks.com/en/machine-learning/index.html#machine-learning-on-databricks	DASF v 1.0	Data Governance and Quality	Catalog and governance, Model management	GOV-16	Novel AI control/capability	no mapping	no mapping	no mapping	no mapping	A.4.4 Tooling resources A.6.2.6 AI system operation and monitoring	no mapping	CM-2:Baseline Configuration,  CM-3:Configuration Change Control,  CM-8:System Component Inventory,  AC-2:Account Management,  AC-3:Access Enforcement,  AC-6:Least Privilege	Documenting and inventorying AI systems -> Inventory deployed AI systems 	Apply a RBAC Model, Respecting the Least Privileged Principle. Ensure ML Applications Comply with Identity Management, Authentication, and Access Control Policies. Ensure ML Applications Comply with Data Security Requirements. Include ML Applications in Asset Management Processes. Ensure ML Projects Follow the Global Process for Integrating Security into Projects.	no mapping
DASF 19	DASF 19: Manage end-to-end machine learning lifecycle 	Governance 4.2, Model 7.1	Databricks includes a managed version of MLflow featuring enterprise security controls and high availability. It supports functionalities like experiments, run management and notebook revision capture. MLflow on Databricks allows tracking and measuring machine learning model training runs, logging model training artifacts and securing machine learning projects.	Databricks — Implementation	Databricks Managed	https://docs.databricks.com/en/mlflow/index.html	https://learn.microsoft.com/en-us/azure/databricks/mlflow/	https://docs.gcp.databricks.com/en/mlflow/index.html	DASF v 1.0	Model Management and MLOps	ML algorithm, Evaluation, Model build, Model management, ML Operations	Out of the box	Novel AI Control/Capability	no mapping	no mapping	no mapping	no mapping	A.6.1.2 Objectives for responsible development of AI system A.6.2.6 AI system operation and monitoring A.6.2.8 AI system recording of event logs A.4.3 Data resources A.7.2 Data for development and enhancement of AI system A.7.4 Quality of data for AI systems 	no mapping	SA-3:System Development Life Cycle,  SA-4:Acquisition Process,  SA-8:Security and Privacy Engineering Principles,  CM:Configuration Management Family,  CA-2:Control Assessments,  CA-7:Continuous Monitoring,  CA-8:Penetration Testing	Development of AI software -> Change control over AI models	Ensure ML Projects Follow the Global Process for Integrating Security into Projects. Mapping Security Controls to the ML Lifecycle Stages. Apply Documentation Requirements to AI Projects. Implement Processes to Maintain Security Levels of ML Components Over Time.	Article 14.2 High-Risk AI System   Article 9 High-Risk AI System 
DASF 20	DASF 20: Track ML training runs 	Algorithms 5.1, Algorithms 5.3	MLflow tracking facilitates the automated recording and retrieval of experiment details, including algorithms, code, datasets, parameters, configurations, signatures and artifacts.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/mlflow/tracking.html	https://learn.microsoft.com/en-us/azure/databricks/mlflow/tracking	https://docs.gcp.databricks.com/en/mlflow/tracking.html	DASF v 1.0	Model Management and MLOps	ML algorithm, Evaluation, Model build, ML Operations	Out of the box	Novel AI Control/Capability	no mapping	no mapping	no mapping	no mapping	A.6.2.4 AI system verification and validation	no mapping	no mapping	no mapping	no mapping	no mapping
DASF 21	DASF 21: Monitor data and AI system from a single pane of glass 	Raw data 1.3, Governance 4.2, Algorithms 5.2	Databricks Lakehouse Monitoring offers a single pane of glass to centrally track tables’ data quality and statistical properties and automatically classifies data. It can also track the performance of machine learning models and model serving endpoints by monitoring inference tables containing model inputs and predictions through a single pane of glass.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/lakehouse-monitoring/index.html	https://learn.microsoft.com/en-us/azure/databricks/lakehouse-monitoring/	N/A	DASF v 1.0	Monitoring and Evaluation	Data preparation, Model Serving: Inference responses, ML Operations	Features available to implement control and manually verify	Novel AI control/capability	no mapping	no mapping	no mapping	no mapping	A.6.2.6 AI system operation and monitoring A.6.2.8 AI system recording of event logs	no mapping	no mapping	AI system logging and monitoring -> Monitor AI system inputs and outputs  	no mapping	no mapping
DASF 22	DASF 22: Build models with all representative, accurate and relevant data sources 	Evaluation 6.2, Model 7.3	Harnessing internal data and intellectual property to customize large AI models can offer a significant competitive edge. However, this process can be complex, involving coordination across various parts of the organization. The Data Intelligence Platform addresses this challenge by integrating data across traditionally isolated departments and systems. This integration facilitates a more cohesive data and AI strategy, enabling the effective training, testing and evaluation of models using a comprehensive dataset. Use caution when preparing data for traditional models and GenAI training to ensure that you are not unintentionally including data that causes legal conflicts, such as copyright violations, privacy violations or HIPAA violations.	Databricks — Implementation	Customer configured, Databricks enforced	https://www.databricks.com/product/data-lakehouse	https://www.databricks.com/product/data-lakehouse	https://www.databricks.com/product/data-lakehouse	DASF v 1.0	Model Management and MLOps	Raw data, ML algorithm	Features available to implement control and manually verify	Novel AI control/capability	no mapping	no mapping	LLM03: Training Data Poisoning LLM05: Supply Chain Vulnerabilities	no mapping	A.6.2.4 AI system verification and validation A.7 Data for AI systems A.7.2 Data for development and enhancement of AI system A.7.3 Acquisition of data A.7.4 Quality of data for AI systems A.7.5 Data provenance A.7.6 Data preparation A.9 Use of AI systems A.9.2 Processes for responsible use of AI systems A.9.3 Objectives for responsible use of AI system A.9.4 Intended use of the AI system	no mapping	SI-12:Information Management and Retention,  SI-18:Personally Identifiable Information Quality Operations,  RA-5:Vulnerability Monitoring and Scanning,  RA-7:Risk Response	Supply chain ->  Verification of origin and integrity of AI assets  Model robustness -> Adversarial training 	Control All Data Used by the ML Model. Ensure Reliable Sources Are Used. Use Methods to Clean the Training Dataset from Suspicious Samples. Implement Processes to Maintain Security Levels of ML Components Over Time.	Article 5.1 Prohibited AI Practices
DASF 23	DASF 23: Register, version, approve, promote, deploy and monitor models 	Model 7.1, Datasets 3.5	MLflow Model Registry supports managing the machine learning model lifecycle with capabilities for lineage tracking, versioning, staging and model serving.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/machine-learning/manage-model-lifecycle/index.html	https://learn.microsoft.com/en-us/azure/databricks/machine-learning/manage-model-lifecycle/	https://docs.gcp.databricks.com/en/machine-learning/manage-model-lifecycle/index.html	DASF v 1.0	Model Management and MLOps	Model management, ML Operations	Features available to implement control and manually verify	Novel AI control/capability	no mapping	no mapping	no mapping	no mapping	A.6.2.5 AI system deployment A.6.2.6 AI system operation and monitoring A.6.2.7 AI system technical documentation A.6.2.8 AI system technical documentation	no mapping	CM-2:Baseline Configuration,  CM-3:Configuration Change Control,  CA-7:Least Functionality,  CA-8:System Component Inventory	With Unity Catalog, organizations can implement a unified governance framework for their structured and unstructured data, machine learning models, notebooks, features, functions, and files, enhancing security and compliance across clouds and platforms. Maintain an updated inventory of high-impact AI use cases, including details on purpose, benefits, risks, and risk management practices.	Apply Documentation Requirements to AI Projects. Ensure ML Projects Follow the Global Process for Integrating Security into Projects. Include ML Applications in Asset Management Processes. Implement Processes to Maintain Security Levels of ML Components Over Time. Ensure ML Applications Comply with Protection Policies and are Integrated to Security Operations Processes. Define and Monitor Indicators for Proper Functioning of the Model.	no mapping
DASF 24	DASF 24: Control access to models and model assets 	Model 7.2, Model Management 8.2, Model Management 8.3, Model Management 8.4, Model Serving - Inference requests 9.1, Model Serving - Inference requests 9.2, Model Serving - Inference requests 9.5, Model Serving - Inference requests 9.6, Model Serving - Inference requests 9.7, Model Serving - Inference response 10.3, Model Serving - Inference response 10.4	Organizations commonly encounter challenges in tracking and controlling access to ML models, auditing their usage, and understanding their evolution in complex machine learning workflows. Unity Catalog integrates with the MLflow Model Registry across model lifecycles. This approach simplifies the management and oversight of ML models, proving particularly valuable in environments with multiple teams and diverse projects.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/machine-learning/manage-model-lifecycle/index.html#control-access-to-models	https://learn.microsoft.com/en-us/azure/databricks/machine-learning/manage-model-lifecycle/#control-access-to-models	https://docs.gcp.databricks.com/en/machine-learning/manage-model-lifecycle/index.html#control-access-to-models	DASF v 1.0	Access and Authentication	Catalog and governance, Model management	GOV-16	Novel AI Control/Capability	AML.M0005 Control Access to ML Models and Data at Rest	no mapping	LLM01: Prompt Injection LLM03: Training Data Poisoning LLM10: Model Theft	ML03:2023 Model Inversion Attack ML05:2023 Model Theft ML10:2023 Model Poisoning	no mapping	A.8.3 Information access restriction A.8.2 Privileged access rights	AC-2, AC-3, AC-6, CM-5, SC family	AI security governance -> Humans can intervene if needed Access to the AI system -> GenAI model Least Privilege  Access to the AI system ->  Restrict access to AI models Access to the AI system -> Restrict access to interact with the AI model Access to the AI system->  Restrict access to the AI engineering environment and AI code 	Apply a RBAC Model, Respecting the Least Privileged Principle. Ensure ML Applications Comply with Identity Management, Authentication, and Access Control Policies. Ensure ML Applications Comply with Data Security Requirements. Ensure Appropriate Protection is Deployed for Test Environments. Reduce the Available Information About the Model. Ensure ML Applications Comply with Third Parties' Security Requirements.  	no mapping
DASF 25	DASF 25: Use retrieval augmented generation (RAG) with large language models (LLMs) 	Evaluation 6.2, Model Serving - Inference requests 9.8	Generating relevant and accurate responses in large language models (LLMs) while avoiding hallucinations requires grounding them in domain-specific knowledge. Retrieval augmented generation (RAG) addresses this by breaking down extensive datasets into manageable segments (“chunks”) that are “vector embedded.” These vector embeddings are mathematical representations that help the model understand and quantify different data segments. As a result, LLMs produce responses that are contextually relevant and deeply rooted in the specific domain knowledge.	Databricks — Implementation	Co-managed	https://docs.databricks.com/en/generative-ai/retrieval-augmented-generation.html	https://learn.microsoft.com/en-us/azure/databricks/generative-ai/retrieval-augmented-generation	N/A	DASF v 1.0	Model Management and MLOps	ML algorithm, Model Serving: Inference requests, ML Operations	Features available to implement control and manually verify	Novel AI Control/Capability	no mapping	no mapping	not available at the time of writing	no mapping	A.4.3 Data resources A.6.1.2 Objectives for responsible development of AI system A.6.1.3 Processes for responsible design and development of AI systems	no mapping	no mapping	no mapping	no mapping	no mapping
DASF 26	DASF 26: Fine-tune large language models (LLMs) 	Model Serving - Inference requests 9.8	Data is your competitive advantage. Use it to customize large AI models to beat your competition. Produce new model variants with tailored LLM response style and structure via fine-tuning. Fine-tune your own LLM with open models to own your IP.	Databricks — Implementation	Co-managed	https://docs.databricks.com/en/large-language-models/foundation-model-training/index.html	https://learn.microsoft.com/en-us/azure/databricks/large-language-models/foundation-model-training/	N/A	DASF v 1.0	Model Management and MLOps	ML algorithm,	Features available to implement control and manually verify	Novel AI Control/Capability	no mapping	no mapping	LLM09.3: Overreliance	no mapping	A.4.3 Data resources A.6.1.2 Objectives for responsible development of AI system A.6.1.3 Processes for responsible design and development of AI systems A.6.2.3 Documentation of AI system design and development	no mapping	no mapping	no mapping	no mapping	no mapping
DASF 27	DASF 27: Pretrain a large language model (LLM)	Raw data 1.8, Model 7.3, Model Serving - Inference requests 9.8	Data is your competitive advantage. Use it to customize large AI models to beat your competition by pretraining models with your data, imbuing the model with domain-specific knowledge, vocabulary and semantics. Pretrain your own LLM with MosaicML to own your IP.	Databricks — Implementation	Co-managed	https://www.databricks.com/glossary/large-language-models-llm#pretraining	https://www.databricks.com/glossary/large-language-models-llm#pretraining	N/A	DASF v 1.0	Model Management and MLOps	ML algorithm,	Features available to implement control and manually verify	Novel AI Control/Capability	no mapping	no mapping	no mapping 	no mapping	A.4.3 Data resources A.6.1.2 Objectives for responsible development of AI system A.6.1.3 Processes for responsible design and development of AI systems A.6.2.3 Documentation of AI system design and development	no mapping	no mapping	AI legal and compliance -> ID and evaluate compliance & legal obligations for AI system development and deployment  AI legal and compliance ->  ID and evaluate any constraints on data used for AI  Supply chain ->  Verification of origin and integrity of AI assets	no mapping	no mapping
DASF 28	DASF 28: Create model aliases, tags and annotations	Model Management 8.1, Model Management 8.3, Model Serving - Inference requests 9.5, Model Serving - Inference requests 9.6, Model Serving - Inference response 10.3, Model Serving - Inference response 10.4	Model aliases in machine learning workflows allow you to assign a mutable, named reference to a specific version of a registered model. This functionality is beneficial for tracking and managing different stages of a model’s lifecycle, indicating the current deployment status of any given model version.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/machine-learning/manage-model-lifecycle/index.html#deploy-and-organize-models-with-aliases-and-tags	https://learn.microsoft.com/en-us/azure/databricks/machine-learning/manage-model-lifecycle/#--deploy-and-organize-models-with-aliases-and-tags	https://docs.gcp.databricks.com/en/machine-learning/manage-model-lifecycle/index.html#deploy-and-organize-models-with-aliases-and-tags	DASF v 1.0	Model Management and MLOps	Catalog and governance, Model management,	Features available to implement control and manually verify	Novel AI Control/Capability	no mapping	no mapping	LLM10.8: Model Theft	ML05:2023 Model Theft	 A.4.2 Resource documentation A.4.3 Data resources A.6.2.6 AI system operation and monitoring	no mapping	CM-2:Baseline Configuration,  CM-8:System Component Inventory,  AC-3:Access Enforcement,  AC-4:Information Flow Enforcement	AI security governance -> Humans can intervene if needed	no mapping	no mapping
DASF 29	DASF 29: Build MLOps workflows	Raw data 1.8, Model Management 8.1, Model Management 8.3	The lakehouse forms the foundation of a data-centric AI platform. Key to this is the ability to manage both data and AI assets from a unified governance solution on the lakehouse. Databricks Unity Catalog enables this by providing centralized access control, auditing, approvals, model workflow, lineage, and data discovery capabilities across Databricks workspaces. These benefits are now extended to MLflow Models with the introduction of Models in Unity Catalog. Through providing a hosted version of the MLflow Model Registry in Unity Catalog, the full lifecycle of an ML model can be managed while leveraging Unity Catalog’s capability to share assets across Databricks workspaces and trace lineage across both data and models.	Databricks — Implementation	Co-managed	https://docs.databricks.com/en/machine-learning/mlops/mlops-workflow.html	https://learn.microsoft.com/en-us/azure/databricks/machine-learning/mlops/mlops-workflow	https://docs.gcp.databricks.com/en/machine-learning/mlops/mlops-workflow.html	DASF v 1.0	Model Management and MLOps	Catalog and governance, Model management, ML Operations	Features available to implement control and manually verify	Novel AI Control/Capability	no mapping	no mapping	LLM05.5, 7: Supply Chain Vulnerabilities LLM10.4: Model Theft	ML01:2023 Input Manipulation Attack ML02:2023 Data Poisoning Attack ML03:2023 Model Inversion Attack ML04:2023 Membership Inference Attack ML05:2023 Model Theft ML06:2023 AI Supply Chain Attacks ML07:2023 Transfer Learning Attack ML08:2023 Model Skewing ML09:2023 Output Integrity Attack ML10:2023 Model Poisoning	A.6.2.5 AI system deployment A.6.2.6 AI system operation and monitoring	no mapping	SA-3:System Development Life Cycle,  SA-4:Acquisition Process,  SA-8:Security and Privacy Engineering Principles,  CM-2:Baseline Configuration,  CM-3:Configuration Change Control,  CM-8:System Component Inventory,  AC-2:Account Management,  AC-3:Access Enforcement,  AU-3:Content of Audit Records,  AU-6:Audit Record Review, Analysis, and Reporting,  PM-31:Continuous Monitoring Strategy	AI security governance -> Humans can intervene if needed Development of AI software -> Change control over AI models  AI legal and compliance -> ID and evaluate compliance & legal obligations for AI system development and deployment  AI legal and compliance ->  ID and evaluate any constraints on data used for AI	Ensure ML applications comply with protection policies and are integrated to security operations processes. Ensure ML projects follow the global process for integrating security into projects. Implement processes to maintain security levels of ML components over time. Apply documentation requirements to AI projects.	no mapping
DASF 30	DASF 30: Encrypt models	Model Management 8.2, Model Management 8.4, Model Serving - Inference requests 9.1, Model Serving - Inference requests 9.2, Model Serving - Inference requests 9.5, Model Serving - Inference requests 9.6, Model Serving - Inference requests 9.7, Model Serving - Inference response 10.2, Model Serving - Inference response 10.3, Model Serving - Inference response 10.4, Model Serving - Inference response 10.5	Databricks Platform secures model assets and their transfer with TLS 1.2+ in-transit encryption. Additionally, Unity Catalog’s managed model registry provides encryption at rest for persisting models, further enhancing security.	Databricks — Out-of-the-box	Databricks Managed	https://docs.databricks.com/en/machine-learning/model-serving/index.html#data-protection-in-model-serving	https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/#data-protection-in-model-serving	https://docs.gcp.databricks.com/en/machine-learning/model-serving/index.html#data-protection-in-model-serving	DASF v 1.0	Data and model security	Model Serving: Inference requests, ML Operations	Out of the box	Traditional Control/Capability	AML.M0012 Encrypt Sensitive Information	M1041 Encrypt Sensitive Information	no mapping	ML01:2023 Input Manipulation Attack ML02:2023 Data Poisoning Attack ML03:2023 Model Inversion Attack ML04:2023 Membership Inference Attack ML05:2023 Model Theft	no mapping	A.8.24 Use of cryptography	SC-8:Transmission Confidentiality and Integrity,  SC-28:Protection of Information at Rest,  MP-4:Media Storage,  AC-3:Access Enforcement,  AU-9:Protection of Audit Information,  AC-17:Remote Access	Access to the AI system->  Restrict access to the AI engineering environment and AI code Encryption -> Encrypt AI artifacts at rest	Ensure ML applications comply with data security requirements.	Article 15.5 Accuracy, Robustness, and Cybersecurity  Article 15.1 Accuracy, Robustness, and Cybersecurity  Article 72 Post-market monitoring
DASF 31	DASF 31: Secure model serving endpoints	Model Management 8.2, Model Management 8.4, Model Serving - Inference requests 9.1, Model Serving - Inference requests 9.2, Model Serving - Inference requests 9.5, Model Serving - Inference requests 9.6, Model Serving - Inference requests 9.7, Model Serving — Inference requests 9.11,  Model Serving — Inference requests 9.12, Model Serving - Inference response 10.2, Model Serving - Inference response 10.3, Model Serving - Inference response 10.4, Model Serving - Inference response 10.5,Model Serving — Inference response 10.6,Platform 12.7: Initial Access	Model serving involves risks of unauthorized data access and model tampering, which can compromise the integrity and reliability of machine learning deployments. Mosaic AI Model Serving addresses these concerns by providing secure-by-default REST API endpoints for MLflow machine learning models, featuring autoscaling, high availability and low latency.	Databricks — Out-of-the-box	Databricks Managed	https://docs.databricks.com/en/machine-learning/model-serving/manage-serving-endpoints.html#manage-permissions-on-your-model-serving-endpoint	https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/manage-serving-endpoints#manage-permissions-on-your-model-serving-endpoint	https://docs.gcp.databricks.com/en/machine-learning/model-serving/manage-serving-endpoints.html	DASF v 1.0	Access and Authentication	Model Serving: Inference requests,	NS-7	Novel AI control/capability	AML.M0019 Control Access to ML Models and Data in Production	no mapping	LLM01: Prompt Injection LLM02: Insecure Output Handling LLM04: Model Denial of Service LLM05: Supply Chain Vulnerabilities LLM10: Model Theft 	ML03:2023 Model Inversion Attack ML04:2023 Membership Inference Attack ML05:2023 Model Theft ML07:2023 Transfer Learning Attack ML08:2023 Model Skewing ML09:2023 Output Integrity Attack ML10:2023 Model Poisoning	no mapping	A.8.20 Networks security A.8.24 Use of cryptography	AC-3:Access Enforcement,  AC-17:Remote Access,  SC-7:Boundary Protection,  SC-23:Session Authenticity,  SI-4:System Monitoring,  SI-10:Information Input Validation,  CM-7:Least Functionality	Access to the AI system -> GenAI model Least Privilege  Access to the AI system -> Restrict access to submit AI inputs and access outputs(front-end and APIs) 	Apply a RBAC model, respecting the least privileged principle. Ensure ML applications comply with identity management, authentication, and access control policies.	no mapping
DASF 32	DASF 32: Streamline the usage and management of various large language model (LLM) providers 	Model Management 8.2, Model Management 8.4, Model Serving - Inference requests 9.1, Model Serving - Inference requests 9.2, Model Serving - Inference requests 9.5, Model Serving - Inference requests 9.6, Model Serving - Inference requests 9.7, Model Serving - Inference response 10.2, Model Serving - Inference response 10.3, Model Serving - Inference response 10.4, Model Serving - Inference response 10.5, Model Serving — Inference response 10.6	External models are third-party models hosted outside of Databricks. Supported by Model Serving AI Gateway, Databricks external models via the AI Gateway allow you to streamline the usage and management of various large language model (LLM) providers, such as OpenAI and Anthropic, within an organization. You can also use Mosaic AI Model Serving as a provider to serve predictive ML models, which offers rate limits for those endpoints. As part of this support, Model Serving offers a high-level interface that simplifies the interaction with these services by providing a unified endpoint to handle specific LLM-related requests. In addition, Databricks support for external models provides centralized credential management. By storing API keys in one secure location, organizations can enhance their security posture by minimizing the exposure of sensitive API keys throughout the system. It also helps to prevent exposing these keys within code or requiring end users to manage keys safely.	Databricks — Out-of-the-box	Customer configured, Databricks enforced	https://docs.databricks.com/en/generative-ai/external-models/index.html	https://learn.microsoft.com/en-us/azure/databricks/generative-ai/external-models/	https://docs.gcp.databricks.com/en/generative-ai/external-models/index.html	DASF v 1.0	Access and Authentication	Model Serving: Inference requests,	Features available to implement control and manually verify	Novel AI Control/Capability	AML.M0009 Use Multi-Modal Sensors	no mapping	LLM01: Prompt Injection LLM02: Insecure Output Handling LLM04: Model Denial of Service LLM05: Supply Chain Vulnerabilities LLM10: Model Theft 	no mapping	A.4.4 Tooling resources A.6.2.6 AI system operation and monitoring	no mapping	no mapping	Access to the AI system -> Model Rate Limiting / Throttling 	no mapping	no mapping
DASF 33	DASF 33: Manage credentials securely	Model 7.2, Model Management 8.2, Model Serving — Inference requests 9.11,  Model Serving — Inference requests 9.12	Databricks Secrets stores your credentials and references them in notebooks, scripts, configuration properties and jobs. Integrating with heterogeneous systems requires managing a potentially large set of credentials and safely distributing them across an organization. Instead of directly entering your credentials into a notebook, use Databricks Secrets to store your credentials and reference them in notebooks and jobs to prevent credential leaks through models. Databricks secret management allows users to use and share credentials within Databricks securely. You can also choose to use a third-party secret management service, such as AWS Secrets Manager or a third-party secret manager.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/security/secrets/index.html	https://learn.microsoft.com/en-us/azure/databricks/security/secrets/	https://docs.gcp.databricks.com/en/security/secrets/index.html	DASF v 1.0	Access and Authentication	Catalog and governance, Model Serving: Inference requests, ML Operations	DP-1	Traditional Control/Capability	no mapping	M1043 Credential Access Protection	no mapping	no mapping	no mapping	A.8.5 Secure Authentication	IA-2:Identification and Authentication (Organizational Users),  IA-5:Authenticator Management,  IA-8:Identification and Authentication (Non-Organizational Users),  AC-2:Account Management,  AC-6:Least Privilege,  AU-2:Event Logging,  CM-6:Configuration Settings,  PS-4:Personnel Termination,  PS-6:Access Agreements	Access to the AI system->  Restrict access to the AI engineering environment and AI code	no mapping	no mapping
DASF 34	DASF 34: Run models in multiple layers of isolation	Model 7.1, Model Serving - Inference requests 9.3	Databricks Serverless Compute provides a secure-by-design model serving service featuring defense-in-depth controls like dedicated VMs, network segmentation, and encryption for data in transit and at rest. It adheres to the principle of least privilege for enhanced security.	Databricks — Out-of-the-box	Databricks Managed	https://docs.databricks.com/en/machine-learning/model-serving/index.html#data-protection-in-model-serving	https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/#data-protection-in-model-serving	https://docs.gcp.databricks.com/en/machine-learning/model-serving/index.html	DASF v 1.0	Platform and System Security	Model Serving: Inference requests, ML Operations	Out of the box	Novel AI control/capability	AML.M0017 Model Distribution Methods	M1048  Application Isolation and Sandboxing M1038  Execution Prevention M1050  Exploit Protection M1026 Privileged Account Management  	LLM10: Model Theft 	ML03:2023 Model Inversion Attack ML04:2023 Membership Inference Attack ML05:2023 Model Theft ML07:2023 Transfer Learning Attack ML08:2023 Model Skewing ML09:2023 Output Integrity Attack ML10:2023 Model Poisoning	no mapping	A.8.22 Segregation of networks	SC-2:Separation of System and User Functionality,  SC-3:Security Function Isolation,  SC-7:Boundary Protection,  SC-28:Protection of Information at Rest,  SC-39:Process Isolation,  CM-7:Least Functionality	Access to the AI system ->  Restrict access to AI models	no mapping	no mapping
DASF 35	DASF 35: Track model performance 	Evaluation 6.3,Model Serving - Inference response 10.1	Databricks Lakehouse Monitoring provides performance metrics and data quality statistics across all account tables. It tracks the performance of machine learning models and model serving endpoints by observing inference tables with model inputs and predictions.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/lakehouse-monitoring/index.html	https://learn.microsoft.com/en-us/azure/databricks/lakehouse-monitoring/	N/A	DASF v 1.0	Monitoring and Evaluation	Model Serving: Inference responses, ML Operations	Features available to implement control and manually verify	Novel AI control/capability	no mapping	no mapping	no mapping	ML03:2023 Model Inversion Attack ML08:2023 Model Skewing	A.6.2.4 AI system verification and validation	no mapping	AU-2:Event Logging,  AU-6:Audit Record Review, Analysis, and Reporting,  CA-7:Continuous Monitoring 	no mapping	Define and monitor indicators for proper functioning of the model. Ensure that the model is sufficiently resilient to the environment in which it will operate. Integrate poisoning control after the 'model evaluation' phase.	Article 72 Post-market monitoring
DASF 36	DASF 36: Set up monitoring alerts 	Raw data 1.3, Model Serving - Inference response 10.1	Databricks SQL alerts can monitor the metrics table for security-based conditions, ensuring data integrity and timely response to potential issues: - Statistic range alert: Triggers when a specific statistic, such as the fraction of missing values, exceeds a predetermined threshold - Data distribution shift alert: Activates upon shifts in data distribution, as indicated by the drift metrics table - Baseline divergence alert: Alerts if data significantly diverges from a baseline, suggesting potential needs for data analysis or model retraining, particularly in InferenceLog analysis	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/lakehouse-monitoring/monitor-alerts.html	https://learn.microsoft.com/en-us/azure/databricks/lakehouse-monitoring/monitor-alerts	N/A	DASF v 1.0	Monitoring and Evaluation	Model Serving: Inference responses, ML Operations	Features available to implement control and manually verify	Novel AI control/capability	no mapping	no mapping	LLM03: Training Data Poisoning,  LLM10: Model Theft 	ML08:2023 Model Skewing	A.6.2.6 AI system operation and monitoring A.6.2.8 AI system recording of event logs	no mapping	AU-2:Event Logging,  AU-5:Response to Audit Logging Process Failures,  AU-6:Audit Record Review, Analysis, and Reporting,  CA-7:Continuous Monitoring,  SI-4:System Monitoring	AI system logging and monitoring -> Monitor AI system inputs and outputs 	Define and monitor indicators for proper functioning of the model. Include ML applications into detection and response to security incident processes.	no mapping
DASF 37	DASF 37: Set up inference tables for monitoring and debugging models	Model Serving - Inference requests 9.1, Model Serving - Inference requests 9.2, Model Serving - Inference requests 9.3, Model Serving - Inference requests 9.4, Model Serving - Inference requests 9.5, Model Serving - Inference requests 9.6, Model Serving - Inference requests 9.7, Model Serving - Inference response 10.1, Model Serving - Inference response 10.3, Model Serving - Inference response 10.4, Model Serving — Inference response 10.6	Databricks inference tables automatically record incoming requests and outgoing responses to model serving endpoints, storing them as a Unity Catalog Delta table. This table can be used to monitor, debug and enhance ML models. By coupling inference tables with Lakehouse Monitoring, customers can also set up automated monitoring jobs and alerts on inference tables, such as monitoring text quality or toxicity from endpoints serving LLMs, etc. Critical applications of an inference table include: - Retraining dataset creation: Building datasets for the next iteration of your models - Quality monitoring: Keeping track of production data and model performance - Diagnostics and debugging: Investigating and resolving issues with suspicious inferences - Mislabeled data identification: Compiling data that needs relabeling	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/machine-learning/model-serving/inference-tables.html	https://learn.microsoft.com/en-us/azure/databricks/machine-learning/model-serving/inference-tables	N/A	DASF v 1.0	Monitoring and Evaluation	Model Serving: Inference responses, ML Operations	Features available to implement control and manually verify	Novel AI control/capability	no mapping	no mapping	no mapping	no mapping	A.6.2.6 AI system operation and monitoring A.6.2.8 AI system recording of event logs	no mapping	AU-2:Event Logging,  AU-3:Content of Audit Records,  AU-6:Audit Record Review, Analysis, and Reporting,  CM-12:Information Location	AI system logging and monitoring -> Log AI system inputs and outputs 	no mapping	no mapping
DASF 38	DASF 38: Platform security — penetration testing, red teaming, bug bounty and vulnerability management	Platform 12.1	Mitigating attacks on infrastructure hosting AI services, including AI red teaming for large language models, is crucial for safe model development and deployment. Regular security and penetration testing help identify and address infrastructure vulnerabilities before attackers can exploit them. Databricks operates a formal, documented vulnerability management program overseen by the Chief Security Officer (CSO). The program is management-approved, reviewed annually, and communicated to all relevant internal parties. AI red teaming, especially for large language models, is an essential component of ensuring model safety and security. Databricks conducts regular AI red teaming on models and systems developed internally. 	Databricks — Out-of-the-box	Databricks Managed	https://www.databricks.com/trust/trust#vulnerability-management	https://www.databricks.com/trust/trust#vulnerability-management	https://www.databricks.com/trust/trust#vulnerability-management	DASF v 1.0	Platform and System Security	Catalog and governance, ML Operations	Out of the box	Novel AI control/capability	AML.M0016 Vulnerability Scanning	M1016 Vulnerability Scanning	Not applcable	no mapping	no mapping	A.8.29 Security testing in development and acceptance	CA-8:Penetration Testing,  RA-5:Vulnerability Monitoring and Scanning,  SI-2:Flaw Remediation,  SA-11:Developer Testing and Evaluation 	no mapping	no mapping	no mapping
DASF 39	DASF 39: Platform security — Incident Response Team 	Platform 12.2, Platform 12.3	Databricks has established a formal incident response plan that outlines key elements such as roles, responsibilities, escalation paths and external communication protocols. The platform handles over 9TB of audit logs daily, aiding customer and Databricks security investigations. A dedicated security incident response team operates an internal Databricks instance, consolidating essential log sources for thorough security analysis. Databricks ensures continual operational readiness with a 24/7/365 on-call rotation. Additionally, a proactive hunting program and a specialized detection team support the incident response program and require periodic AI audits and establish protocols for incident reporting, including logs review, performance monitoring, and procedures to report and address misuse.	Databricks — Out-of-the-box	Databricks Managed	https://www.databricks.com/trust/trust#security-investigations-and-incident-response	https://www.databricks.com/trust/trust#security-investigations-and-incident-response	https://www.databricks.com/trust/trust#security-investigations-and-incident-response	DASF v 1.0	Platform and System Security	Catalog and governance, ML Operations	Out of the box	Traditional Control/Capability	no mapping	 M1040 Behavior Prevention on Endpoint  M1031 Network Intrusion Prevention  M1019  Threat Intelligence Program	no mapping	no mapping	A.3.3 Reporting of concerns	A.5.24 Information security incident management planning and preparation A.5.25 Assessment and decision on in- formation security events A.5.26 Response to Information Security incidents A.5.27 Learning from Information Security Incidents A.5.28 Collection of evidence A.6.8 Information security event reporting	IR-1:Policy and Procedures,  IR-2:Incident Response Training,  IR-3:Incident Response Testing,  IR-4:Incident Handling,  IR-8:Incident Response Plan,  AU-6:Audit Record Review, Analysis, and Reporting,  CP-2:Contingency Plan	Resilience of the AI system -> Updating incident response for AI specifics   	Include ML applications in detection and response to security incident processes.	Article 17.1 Quality Management System
DASF 40	DASF 40: Platform security — internal access 	Platform 12.4	Databricks personnel, by default, do not have access to customer workspaces or production environments. Access may be temporarily requested by Databricks staff for purposes such as investigating outages, security events or supporting deployments. Customers have the option to disable this access. Additionally, staff activity within these environments is recorded in customer audit logs. Accessing these areas requires multi-factor authentication, and employees must connect to the Databricks VPN.	Databricks — Out-of-the-box	Databricks Managed	https://www.databricks.com/trust/trust#internal-access	https://www.databricks.com/trust/trust#internal-access	https://www.databricks.com/trust/trust#internal-access	DASF v 1.0	Platform and System Security	Catalog and governance, ML Operations	Out of the box	Traditional Control/Capability	no mapping	no mapping	no mapping	ML08:2023 Model Skewing	no mapping	A.8.2 Privileged access rights	AC-1:Policy and Procedures,  AC-2:Account Management,  AC-3:Access Enforcement,  AC-6:Least Privilege,  AT-2:Literacy Training and Awareness,  AU-9:Protection of Audit Information,  CM-5:Access Restrictions for Change,  PS-2:Position Risk Designation 	no mapping	Apply a RBAC model, respecting the least privileged principle. Ensure ML applications comply with identity management, authentication, and access control policies. Ensure appropriate protection is deployed for test environments.	no mapping
DASF 41	DASF 41: Platform security — secure SDLC 	Platform 12.5	Databricks engineering integrates security throughout the software development lifecycle (SDLC), encompassing both technical and process-level controls under the oversight of our chief security officer (CSO). Activities within our SDLC include: - Code peer reviews - Static and dynamic scans for code and containers, including dependencies - Feature-level security reviews - Annual software engineering security training - Cross-organizational collaborations between security, product management, product security and security champions These development controls are augmented by internal and external penetration testing programs, with findings tracked for resolution and reported to our executive team. Databricks’ processes undergo an independent annual review, the results of which are published in our SOC 2 Type 2 report, available upon request.	Databricks — Out-of-the-box	Databricks Managed	https://www.databricks.com/trust/trust#secure-software-development-lifecycle	https://www.databricks.com/trust/trust#secure-software-development-lifecycle	https://www.databricks.com/trust/trust#secure-software-development-lifecycle	DASF v 1.0	Platform and System Security	Catalog and governance, ML Operations	Out of the box	Traditional Control/Capability	no mapping	M1054 Software Configuration	no mapping	no mapping	no mapping	A.6.3 Information security awareness, education and training A.8.4 Access to source code A.8.25 Secure development life cycle A.8.26 Application security require- ments A.8.27 Secure system architecture and engineering principles A.8.28 Secure coding 	SA-3:System Development Life Cycle,  SA-4:Acquisition Process,  SA-8:Security and Privacy Engineering Principles,  SA-11:Developer Testing and Evaluation,  CM-2:Baseline Configuration,  CM-3:Configuration Change Control,  PM-14:Testing, Training, and Monitoring	Development of AI software -> Provide AI security training to AI builders and deployers Development of AI software -> Change control over AI models Development of AI software -> Inspection of AI software assets 	Ensure ML projects follow the global process for integrating security into projects. Check the vulnerabilities of the components used so that they have an appropriate security level. Implement processes to maintain security levels of ML components over time. Integrate ML specificities to existing security policies.	no mapping
DASF 42	DASF 42: Employ data-centric MLOps and LLMOps 	Data Prep 2.1,  Data Prep 2.2, Data Prep 2.3, Data Prep 2.4, Governance 4.2, Algorithms 5.1, Algorithms 5.3, Evaluation 6.1, Evaluation 6.3,Model 7.1, Model 7.2, Model 7.3, Model Management 8.3, Operations 11.1	MLOps enhances efficiency, scalability, security and risk reduction in machine learning projects. Databricks integrates with MLflow, focusing on enterprise reliability, security and scalability for managing the machine learning lifecycle. The latest update to MLflow introduces new LLMOps features for better management and deployment of large language models (LLMs). This includes integrations with Hugging Face Transformers, OpenAI and the external models in Mosaic AI Model Serving. MLflow also integrates with LangChain and a prompt engineering UI, facilitating generative AI application development for use cases such as chatbots, document summarization and text classification.	Databricks — Implementation	Customer-managed	https://www.databricks.com/resources/ebook/the-big-book-of-mlops	https://www.databricks.com/resources/ebook/the-big-book-of-mlops	https://www.databricks.com/resources/ebook/the-big-book-of-mlops	DASF v 1.0	Model Management and MLOps	ML algorithm, Model build, Model Serving: Inference requests, Model Serving: Inference responses, ML Operations	Features available to implement control and manually verify	Novel AI Control/Capability	no mapping	no mapping	LLM03: Training Data Poisoning,  LLM05: Supply Chain Vulnerabilities LLM10: Model Theft 	ML08:2023 Model Skewing	A.6.2 AI system life cycle A.6.2.2 AI system requirements and specification A.6.2.3 Documentation of AI system design and development A.6.2.4 AI system verification and validation A.6.2.5 AI system deployment A.6.2.6 AI system operation and monitoring A.6.2.8 AI system recording of event logs A.7 Data for AI systems A.7.2 Data for development and enhancement of AI system A.7.3 Acquisition of data A.7.4 Quality of data for AI systems A.7.5 Data provenance A.7.6 Data preparation	no mapping	SC-8:Transmission Confidentiality and Integrity,  SC-12:Cryptographic Key Establishment and Management,  SC-28:Protection of Information at Rest,  AC-2:Account Management,  AC-3:Access Enforcement,  AC-5:Separation of Duties,  AC-6:Least Privilege,  SA-8:Security and Privacy Engineering Principles,  AU-2:Event Logging,  AU-6:Audit Record Review, Analysis, and Reporting,  SI-2:Flaw Remediation,  SI-7:Software, Firmware, and Information Integrity	Development of AI software -> Provide AI security training to AI builders and deployers Development of AI software -> Change control over AI models  Supply chain ->  Verification of origin and integrity of AI assets	Apply a RBAC model, respecting the least privileged principle. Ensure ML applications comply with identity management, authentication, and access control policies. Ensure appropriate protection is deployed for test environments.	no mapping
DASF 43	DASF 43: Use access control lists 	Data Prep 2.3, Algorithms 5.3, Model 7.1	Databricks access control lists (ACLs) enable you to configure permissions for accessing and interacting with workspace objects, including folders, notebooks, experiments, models, clusters, pools, jobs, Delta Live Tables pipelines, alerts, dashboards, queries and SQL warehouses.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/security/auth-authz/access-control/index.html	https://learn.microsoft.com/en-us/azure/databricks/security/auth-authz/access-control/	https://docs.gcp.databricks.com/en/security/auth-authz/access-control/index.html	DASF v 1.0	Access and Authentication	Catalog and governance,	INFO-8, INFO-9, INFO-10	Traditional Control/Capability	no mapping	M1039 Environment Variable Permissions M1052 User Account Control M1018 User Account Management	no mapping	no mapping	no mapping	A.5.15 Access control A.8.3 Information access restriction	AC-3:Access Enforcement,  AC-6:Least Privilege,  AC-17:Remote Access	Access to the AI system -> Restrict access to data used for AI Access to the AI system ->  Restrict access to AI models Access to the AI system->  Restrict access to the AI engineering environment and AI code	Apply a RBAC model, respecting the least privileged principle. Ensure ML applications comply with identity management, authentication, and access control policies	no mapping
DASF 44	DASF 44: Triggering actions in response to a specific event 	Evaluation 6.1, Operations 11.1	Webhooks in the MLflow Model Registry enable you to automate machine learning workflow by triggering actions in response to specific events. These webhooks facilitate seamless integrations, allowing for the automatic execution of various processes. For example, webhooks are used for: - CI workflow trigger: Validate your model automatically when creating a new version - Team notifications: Send alerts through a messaging app when a model stage transition request is received - Model fairness evaluation: Invoke a workflow to assess model fairness and bias upon a production transition request - Automated deployment: Trigger a deployment pipeline when a new tag is created on a model	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/mlflow/model-registry-webhooks.html	https://learn.microsoft.com/en-us/azure/databricks/mlflow/model-registry-webhooks	https://docs.gcp.databricks.com/en/mlflow/model-registry-webhooks.html	DASF v 1.0	Model Management and MLOps	Model management, ML Operations	Features available to implement control and manually verify	Novel AI Control/Capability	no mapping	no mapping	no mapping	no mapping	A.6.2.6 AI system operation and monitoring	A.8.16 Monitoring Activities	AU-2:Event Logging,  SI-4:System Monitoring,  CM-6:Configuration Settings	no mapping	Include ML applications into detection and response to security incident processes. Define and monitor indicators for proper functioning of the model.	no mapping
DASF 45	DASF 45: Evaluate models	Evaluation 6.1, Evaluation 6.2, Evaluation 6.3, Model 7.3, Model Serving - Inference requests 9.5, Model Serving - Inference requests 9.6, Model Serving - Inference response 10.4, Operations 11.1	Model evaluation is a critical component of the machine learning lifecycle. It provides data scientists with the tools to measure, interpret and explain the performance of their models. MLflow plays a critical role in accelerating model development by offering insights into the reasons behind a model’s performance and guiding improvements and iterations. MLflow offers many industry-standard native evaluation metrics for classical machine learning algorithms and LLMs, and also facilitates the use of custom evaluation metrics.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/mlflow/llm-evaluate.html	https://learn.microsoft.com/en-us/azure/databricks/mlflow/llm-evaluate	https://docs.gcp.databricks.com/en/mlflow/llm-evaluate.html	DASF v 1.0	Monitoring and Evaluation	Evaluation,	Features available to implement control and manually verify	Novel AI Control/Capability	AML.M0008 Validate ML Model	no mapping	no mapping	no mapping	A.6.1.2 Objectives for responsible development of AI system A.6.1.3 Processes for responsible AI system design and development A.6.2.4 AI system verification and validation	no mapping	no mapping	Development of AI software -> Change control over AI models	Define and monitor indicators for proper functioning of the model. Conduct a risk analysis of the ML application.	Article 72 Post-market monitoring
DASF 46	DASF 46: Store and retrieve embeddings securely 	Model Serving - Inference requests 9.1, Model Serving - Inference requests 9.2, Model Serving - Inference requests 9.5, Model Serving - Inference requests 9.6, Model Serving - Inference requests 9.7, Model Serving - Inference requests 9.8, Model Serving - Inference requests 9.9, Model Serving - Inference requests 9.10, Model Serving - Inference response 10.4	Mosaic AI Vector Search is a vector database that is built into the Databricks Data Intelligence Platform and integrated with its governance and productivity tools. A vector database is a database that is optimized to store and retrieve embeddings. Embeddings are mathematical representations of the semantic content of data, typically text or image data. Embeddings are usually generated by feature extraction models for text, image, audio or multi-modal data, and are a key component of many GenAI applications that depend on finding documents or images that are similar to each other. Examples are RAG systems, recommender systems, and image and video recognition. Databricks implements the following security controls to protect your data: Every customer request to Vector Search is logically isolated, authenticated and authorized  Mosaic AI Vector Search encrypts all data at rest (AES-256) and in transit (TLS 1.2+)  and optionally can be encrypted with Customer Managed Keys (CMK). 	Databricks — Implementation	Co-managed	https://docs.databricks.com/en/generative-ai/vector-search.html	https://learn.microsoft.com/en-us/azure/databricks/generative-ai/vector-search	N/A	DASF v 1.0	Access and Authentication	Model Serving: Inference responses,	GOV-16	Novel AI Control/Capability	no mapping	no mapping	no mapping	no mapping	no mapping	no mapping	AC-2:Account Management,  AC-3:Access Enforcement,  AC-6:Least Privilege,  AC-17:Remote Access,  AU-2:Event Logging,  AU-6:Audit Record Review, Analysis, and Reporting,  AU-9:Protection of Audit Information,  SC-7:Boundary Protection,  SC-8:Transmission Confidentiality and Integrity,  SC-12:Cryptographic Key Establishment and Management,  SC-28:Protection of Information at Rest,  SI-4:System Monitoring,  SI-7:Software, Firmware, and Information Integrity	Access to the AI system-> GenAI model Least Privilege  Encryption -> Encrypt traffic to and from the AI model	Apply a RBAC model, respecting the least privileged principle. Ensure ML applications comply with data security requirements. Ensure appropriate protection is deployed for test environments. Control all data used by the ML model.	no mapping
DASF 47	DASF 47: Compare LLM outputs on set prompts 	Evaluation 6.2	New, no-code visual tools allow users to compare models’ output based on set prompts, which are automatically tracked within MLflow. With integration into Mosaic AI Model Serving, customers can deploy the best model to production. The AI Playground is a chat-like environment where you can test, prompt and compare LLMs.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/large-language-models/ai-playground.html	https://learn.microsoft.com/en-us/azure/databricks/large-language-models/ai-playground	N/A	DASF v 1.0	Monitoring and Evaluation	ML algorithm,	Features available to implement control and manually verify	Novel AI Control/Capability	no mapping	no mapping	no mapping	no mapping	A.6.2.4 AI system verification and validation	no mapping	no mapping	no mapping	no mapping	no mapping
DASF 48	DASF 48: Use hardened Runtime for Machine Learning 	Model 7.3	Databricks Runtime for Machine Learning (Databricks Runtime ML) now automates cluster creation with versatile infrastructure, encompassing pre-built ML/DL libraries and custom library integration. Enhanced scalability and cost management tools optimize performance and expenditure. The refined user interface caters to various expertise levels, while new collaboration features support team-based projects. Comprehensive training resources and detailed documentation complement these improvements.	Databricks — Out-of-the-box	Databricks Managed	https://docs.databricks.com/en/machine-learning/index.html#databricks-runtime-for-machine-learning	https://learn.microsoft.com/en-us/azure/databricks/machine-learning/#--databricks-runtime-for-machine-learning	https://docs.gcp.databricks.com/en/machine-learning/index.html#databricks-runtime-for-machine-learning	DASF v 1.0	Platform and System Security	Model build,	Out of the box	Novel AI control/capability	M1046 Boot Integrity	M1028 Operating System Configuration	no mapping 	no mapping	no mapping	A.8.9 Configuration management	CM-2:Baseline Configuration,  CM-7:Least Functionality,  CM-11:User-Installed Software,  SC-7:Boundary Protection,  SC-8:Transmission Confidentiality and Integrity,  SC-28:Protection of Information at Rest,  SC-39:Process Isolation,  SI-2:Flaw Remediation,  SI-3:Malicious Code Protection,  SI-4:System Monitoring,  SI-7:Software, Firmware, and Information Integrity	no mapping	no mapping	no mapping
DASF 49	DASF 49: Automate LLM evaluation 	Evaluation 6.1, Model Serving - Inference requests 9.8 	The “LLM-as-a-judge” feature in MLflow 2.8 automates LLM evaluation, offering a practical alternative to human judgment. It’s designed to be efficient and cost-effective, maintaining consistency with human scores. This tool supports various metrics, including standard and customizable GenAI metrics, and allows users to select an LLM as a judge and define specific grading criteria.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/generative-ai/agent-evaluation/llm-judge-metrics.html	https://learn.microsoft.com/en-us/azure/databricks/generative-ai/agent-evaluation/llm-judge-metrics	N/A	DASF v 1.0	Monitoring and Evaluation	Evaluation,	Features available to implement control and manually verify	Novel AI Control/Capability	no mapping	no mapping	no mapping	no mapping	A.6.2.4 AI system verification and validation A.9.3 Objectives for responsible use of AI system	no mapping	no mapping	Development of AI software -> Change control over AI models	no mapping	no mapping
DASF 50	DASF 50: Platform compliance	Platform 12.6	Develop your solutions on a platform created using some of the most rigorous security and compliance standards in the world. Get independent audit reports verifying that Databricks adheres to security controls for ISO 27001, ISO 27018, SOC 1, SOC 2, FedRAMP, HITRUST, IRAP, etc.	Databricks — Out-of-the-box	Co-managed	https://www.databricks.com/trust/compliance	https://www.databricks.com/trust/compliance	https://www.databricks.com/trust/compliance	DASF v 1.0	Platform and System Security	Catalog and governance, ML Operations	Out of the box	Traditional Control/Capability	no mapping	no mapping	no mapping	no mapping	A.2.2 AI policy A.2.3 Alignment with other organizational policies	A.5.1 Policies for information security A.5.36 Compliance with policies, rules and standards for information security 	no mapping	no mapping	Ensure ML applications comply with security policies. Assess the regulations and laws the ML application must comply with. Ensure ML applications comply with data security requirements. Ensure ML applications comply with identity management, authentication, and access control policies. Ensure ML applications comply with third parties' security requirements. Ensure ML projects follow the global process for integrating security into projects.	Article 72 Post-market monitoring
DASF 51	DASF 51: Share data and AI assets securely	Raw data 1.1, Raw data 1.6, Raw data 1.7, Datasets 3.1, Model Management 8.1, Model Management 8.2	Databricks Delta Sharing lets you share data and AI assets securely in Databricks with users outside your organization, whether those users use Databricks or not.	Databricks — Out-of-the-box	Co-managed	https://docs.databricks.com/en/data-sharing/index.html	https://learn.microsoft.com/en-us/azure/databricks/data-sharing/	https://docs.gcp.databricks.com/en/data-sharing/index.html	DASF v 1.0	Data and model security	Catalog and governance,	GOV-17, GOV-18, GOV-19, INFO-18	Novel AI control/capability	no mapping	no mapping	no mapping	no mapping	no mapping	A.5.14 Information transfer	AC-3:Access Enforcement,  AC-6:Least Privilege,  AC-21:Information Sharing,  SC-8:Transmission Confidentiality and Integrity,  SC-28:Protection of Information at Rest,  SI-7:Software, Firmware, and Information Integrity,  SR-2:Supply Chain Risk Management Plan,  SR-8:Notification Agreements	no mapping	Apply a RBAC model, respecting the least privilege principle. Ensure ML applications comply with identity management, authentication, and access control policies. Ensure ML applications comply with data security requirements. Ensure ML applications comply with third parties' security requirements. Conduct a risk analysis of the ML application.	no mapping
DASF 52	DASF 52: Source code control 	Data Prep 2.1, Model 7.4	Databricks’ Git Repository integration supports effective code and third-party libraries management, enhancing customer control over their development environment.	Databricks — Out-of-the-box	Customer configured, Databricks enforced	https://docs.databricks.com/en/repos/index.html	https://learn.microsoft.com/en-us/azure/databricks/repos/	https://docs.gcp.databricks.com/en/repos/index.html	DASF v 1.0	Special Security Measures	Data Preparation, Development, Evaluation	INFO-11, INFO-38 	Traditional Control/Capability		no mapping	no mapping	no mapping	A.4.4 Tooling resources A.6.2.3 Documentation of AI system design and development	A.8.25 Secure development life cycle	CM-2:Baseline Configuration,  CM-3:Configuration Change Control,  CM-10:Software Usage Restrictions,  SI-7:Software, Firmware, and Information Integrity,  SA-10:Information Input Validation,  SA-11:Error Handling	Development of AI software -> Version control code specific to AI 	no mapping	no mapping
DASF 53	DASF 53: Third-party library control 	Algorithms 5.4, Model 7.3, Model 7.4	Databricks’ library management system allows administrators to manage the installation and usage of third-party libraries effectively. This feature enhances the security and efficiency of systems, pipelines and data by giving administrators precise control over their development environment.	Databricks — Out-of-the-box	Customer configured, Databricks enforced	https://docs.databricks.com/en/data-governance/unity-catalog/manage-privileges/allowlist.html	https://learn.microsoft.com/en-us/azure/databricks/data-governance/unity-catalog/manage-privileges/allowlist	https://docs.gcp.databricks.com/en/data-governance/unity-catalog/manage-privileges/allowlist.html	DASF v 1.0	Special Security Measures	Data Preparation, Development, Evaluation	INFO-11	Traditional Control/Capability	AML.M0011 Restrict Library Loading	M1033 Limit Software Installation M1044 Restrict Library Loading	no mapping	no mapping	A.4.4 Tooling resources A.6.2.3 Documentation of AI system design and development	A.8.25 Secure development life cycle	CM-7:Least Functionality,  CM-10:Software Usage Restrictions,  SI-2:Flaw Remediation,  SI-7:Software, Firmware, and Information Integrity,  SR-2:Supply Chain Risk Management Plan,  SR-6:Supplier Assessments and Reviews	Development of AI software -> Inspection of AI software assets  Supply chain ->  Verification of origin and integrity of AI assets	Ensure reliable sources are used	no mapping
DASF 54	DASF 54: Implement AI guardrails	Model Serving - Inference requests 9.1, Model Serving - Inference requests 9.2, Model Serving - Inference requests 9.5, Model Serving - Inference requests 9.6, Model Serving - Inference requests 9.8,  Model Serving — Inference requests 9.12,Model Serving — Inference response 10.6 	AI Guardrails allow users to configure and enforce data compliance at the model serving endpoint level and to reduce harmful content on any requests sent to the underlying model. Bad requests and responses are blocked, and a default message is returned to the user. You can configure and enforce data compliance at the model serving endpoint level and reduce harmful content on any requests sent to the underlying model with AI Guardrails. With AI Guardrails, you can configure the following controls on your AI system: - Safety filtering prevents your model from interacting with unsafe and harmful content, like violent crime, self-harm, and hate speech. - Personally identifiable information (PII) detection to detect any sensitive information (such as names, addresses, and credit card numbers) for users - Topic moderation to list a set of allowed topics. Given a chat request, this guardrail flags the request if its topic is not one of the permitted topics. - Keyword filtering will specify different sets of invalid keywords for both the input and the output. One potential use case for keyword filtering is so the model does not talk about competitors.  	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/ai-gateway/index.html#define-guardrails	https://learn.microsoft.com/en-us/azure/databricks/ai-gateway/	N/A	DASF v 1.1	Platform and System Security	Model Serving: Inference responses,	Features available to implement control and manually verify	Novel AI Control/Capability	no mapping	no mapping	no mapping	no mapping	A.9 Use of AI systems A.9.2 Processes for responsible use of AI systems A.9.3 Objectives for responsible use of AI system A.9.4 Intended use of the AI system	no mapping	no mapping	Filtering and sanitizing AI data, inputs, and outputs -> Output filtering	no mapping	Article 5.1 Prohibited AI Practices
DASF 55	DASF 55: Monitor audit logs	Raw Data 1.1, Raw Data 1.10, Data Prep 2.1, Datasets 3.1, Governance 4.1, Algorithms 5.1, Model 7.1, Model 7.2, Model Management 8.2, Model Management 8.4, Model Serving - Inference requests 9.10, Model Serving — Inference requests 9.11,  Model Serving — Inference requests 9.12, Model Serving — Inference requests 9.13,  Model Serving - Inference response 10.1, Platform 12.7: Initial Access	Audit logs and system tables serve as a centralized operational data store, backed by Delta Lake and governed by Unity Catalog. Audit logs and system tables can be used for a variety of purposes, from user activity, model serving events, and cost monitoring to audit logging. Databricks recommends that customers configure system tables and set up automated monitoring and alerting to meet their needs. The blog post Improve Lakehouse Security Monitoring Using System Tables in Databricks Unity Catalog is a good starting point to help customers get started.   Customers that are using Enhanced Security Monitoring or the Compliance Security Profile can monitor and alert on suspicious activity detected by the behavior-based malware and file integrity monitoring agents.	Databricks — Configuration	Co-managed	https://docs.databricks.com/en/admin/system-tables/index.html	https://learn.microsoft.com/en-us/azure/databricks/admin/system-tables/	https://docs.gcp.databricks.com/en/admin/system-tables/index.html	DASF v 1.1	Platform and System Security	All	GOV-3, GOV-34	Traditional Control/Capability	no mapping	M1047 Audit	no mapping 	ML09:2023 Output Integrity Attack	A.6.2.6 AI system operation and monitoring A.6.2.8 AI system recording of event logs	A.8.15 Logging A.8.16 Monitoring Activities	AU-6:Audit Record Review, Analysis, and Reporting,  AU-7:Audit Record Reduction and Report Generation,  AU-12:Audit Record Generation	AI system logging and monitoring -> Monitor AI system inputs and outputs AI system logging and monitoring -> Monitoring for data, models, and configs for suspicious changes 	Include ML applications into detection and response to security incident processes. Define and monitor indicators for proper functioning of the model. Implement processes to maintain security levels of ML components over time.	Article 17.1 Quality Management System
DASF 56	DASF 56: Restrict outbound connections from models 	 Model 7.1, Model 7.3, Model 7.4, Model Serving - Inference requests 9.1, Model Serving - Inference requests 9.3, Model Serving - Inference requests 9.9	Egress Control enables you to control outbound connections from your Model Serving compute resources.  With this feature, you can restrict access to the internet while allowing access via Unity Catalog Connections or Private Link. Further, this feature blocks direct access to cloud storage (over the shared S3 gateway) to ensure that all data access occurs via Unity Catalog-controlled paths to reduce the risk of data exfiltration.	Databricks — Configuration	Customer configured, Databricks enforced	Private Preview as of November 2024. Ask your account team for more details.	Private Preview as of November 2024. Ask your account team for more details.	Private Preview as of November 2024. Ask your account team for more details.	DASF v 1.1	Platform and System Security	Model Serving	Features available to implement control and manually verify	Novel AI Control/Capability	no mapping	M1037 Filter Network Traffic	LLM01: Prompt Injection LLM03.4, 5: Training Data Poisoning,  LLM06.3: Sensitive Information Disclosure LLM10.2: Model Theft 	no mapping	no mapping	A.8.20 Networks Security A.8.23 Web filtering	AC-4:Information Flow Enforcement,  AC-17:Remote Access,  SC-7:Boundary Protection,  SI-4:System Monitoring	no mapping	Apply a RBAC model, respecting the least privileged principle. Ensure ML applications comply with identity management, authentication, and access control policies. Ensure appropriate protection is deployed for test environments.	Article 15.5 Accuracy, Robustness, and Cybersecurity  Article 15.1 Accuracy, Robustness, and Cybersecurity
DASF 57	DASF 57: Use attribute-based access controls (ABAC)  	Model Serving - Inference requests 9.10,Model Serving — Inference requests 9.13	Attribute-based access controls (ABAC) allow data stewards to set policies on data and AI assets using various criteria like user-defined tags, workspace details, location, identity and time. Whether it’s restricting sensitive data to authorized personnel or adjusting access dynamically based on project needs, ABAC ensures security measures are applied with detailed accuracy. Implement attribute-based access controls (ABAC) to define access policies based on attributes or characteristics of the user or the resource being accessed. Use row level filters and column masking for fine-grained access controls.	Databricks — Implementation	Customer configured, Databricks enforced	https://www.databricks.com/blog/whats-new-databricks-unity-catalog-data-ai-summit-2024	https://www.databricks.com/blog/whats-new-databricks-unity-catalog-data-ai-summit-2024	https://www.databricks.com/blog/whats-new-databricks-unity-catalog-data-ai-summit-2024	DASF v 1.1	Governance and Quality	Catalog and governance,	GOV-16	Traditional Control/Capability	no mapping	no mapping	LLM01.1: Prompt Injection LLM02.1: Insecure Output Handling LLM03.CEV.5: Training Data Poisoning,  LLM06.3: Sensitive Information Disclosure LLM07.4, 5, 6: Insecure Plugin Design LLM08.5, 7: Excessive Agency LLM10.1, 4: Model Theft 	no mapping	no mapping	A.5.15 Access control A.8.3 Information access restriction	AC-3:Access Enforcement,  AC-16:Security and Privacy Attributes	Access to the AI system -> Restrict access to data used for AI	Ensure ML applications comply with identity management, authentication, and access control policies	no mapping
DASF 58	DASF 58: Protect data with filters and masking 	Model Serving - Inference requests 9.10, Model Serving — Inference requests 9.13	Implement filters on sensitive table data using row filters and column masks by harnessing the power of Unity Catalog to secure your data at a granular level. Row filters allow you to apply a filter to a table so that queries return only rows that meet the filter criteria. Column masks let you apply a masking function to a table column.	Databricks — Implementation	Customer configured, Databricks enforced	https://docs.databricks.com/en/tables/row-and-column-filters.html	https://learn.microsoft.com/en-us/azure/databricks/tables/row-and-column-filters	https://docs.gcp.databricks.com/en/tables/row-and-column-filters.html	DASF v 1.1	Governance and Quality	Catalog and governance,	GOV-16	Traditional Control/Capability	no mapping	no mapping	no mapping	no mapping	no mapping	A.8.11 Data masking	AC-3:Access Enforcement,  AC-4:Information Flow Enforcement,  SI-15:Information Output Filtering,  PT-7:Specific Categories of Personally Identifiable Information	Model robustness -> Data minimization during training Filtering and sanitizing AI data, inputs, and outputs ->  Input filtering 	No mapping	Article 5.1 Prohibited AI Practices  Article 10.3 Requirements for data and data governance  Article 10.5 Requirements for data and data governance
DASF 59	DASF 59: Use clean rooms	Raw data 1.1, Raw data 1.7, Model Management 8.2, Model Serving - Inference requests 9.10	Building AI applications today necessitates collaborative efforts across organizations and teams, emphasizing a commitment to privacy and data security. Databricks Clean Rooms offer a secure environment for private collaboration on diverse data and AI tasks, spanning machine learning, SQL queries, Python, R and more. Designed to facilitate seamless collaboration across different cloud and data platforms, Databricks Clean Rooms ensure multiparty collaboration without compromising data privacy or security and enables organizations to build scalable AI applications in a privacy-safe manner.	Databricks — Implementation	Co-managed	https://docs.databricks.com/en/clean-rooms/index.html	https://learn.microsoft.com/en-us/azure/databricks/clean-rooms/	N/A	DASF v 1.1	Data and model security	Catalog and governance,	Features available to implement control and manually verify	Novel AI Control/Capability	no mapping	no mapping	no mapping	no mapping	no mapping	A.5.14 Information transfer A.5.34 Privacy and protection of personal identifiable information (PII)	PE-3:Physical Access Control,  SA-3:System Development Life Cycle,  MP-6:Media Sanitization,  AC-4:Information Flow Enforcement,  SR-9:Tamper Resistance and Detection	no mapping	No mapping	no mapping
DASF 60	DASF 60: Rate limit number of inference queries	Model Serving - Inference requests 9.1, Model Serving - Inference requests 9.2, Model Serving - Inference requests 9.5, Model Serving - Inference requests 9.6, Model Serving - Inference requests 9.7, Model Serving - Inference response 10.2, Model Serving - Inference response 10.3, Model Serving - Inference response 10.4, Model Serving - Inference response 10.5, Model Serving — Inference response 10.6	Enforce request rate limits to manage traffic at the endpoint level on a per-user and per-endpoint basis, effectively controlling access levels and volume.	Databricks — Configuration	Customer configured, Databricks enforced	https://docs.databricks.com/en/ai-gateway/configure-ai-gateway-endpoints.html	https://learn.microsoft.com/en-us/azure/databricks/ai-gateway/configure-ai-gateway-endpoints	https://docs.gcp.databricks.com/en/ai-gateway/configure-ai-gateway-endpoints.html	DASF v 2.0	Platform and System Security	Operations and Platform 	Features available to implement control and manually verify	Novel AI Control/Capability	AML.M0004 Restrict Number of ML Model Queries	no mapping	LLM04.3: Model denial of service  LLM10.6: Model theft	no mapping	no mapping	No mapping	AU-2:Event Logging,  SI-4:System Monitoring,  SI-19:De-identification, AC-3:Access Enforcement,  SC-43:Usage Restrictions	Access to the AI system ->Model Rate Limiting / Throttling	Define and Monitor Indicators for Proper Functioning of the Model.	Article 15.5 Accuracy, Robustness, and Cybersecurity  Article 15.1 Accuracy, Robustness, and Cybersecurity
DASF 61	DASF 61: Train users on AI/ML security		Provide secure coding education and AI vulnerability awareness for model developers. Training personnel who manage AI infrastructure on cybersecurity best practices is essential to prevent human errors that could lead to security breaches.	Databricks - academy	Co-managed	https://www.databricks.com/learn/training/home	https://www.databricks.com/learn/training/home	https://www.databricks.com/learn/training/home	DASF v 2.0	Platform and System Security	Education	Education Certification	Novel AI Control/Capability	AML.M0018 User Training	M1013 Application Developer Guidance  M1017 User Training	no mapping	no mapping	A.4.1 Resource documentation A.6.1.3 Processes for responsible design and development of AI systems A.8.2 System documentation and information for users	A.6.3 Information security awareness, education and training	AT-2:Literacy Training and Awareness,  AT-3:Role-Based Training	Development of AI software -> Provide AI security training to AI builders and deployers	Governments and related institutions have new responsibilities in raising awareness regarding the impact of threats on machine learning. It is important to educate data scientists on the perils of threats and on the design of security controls before machine learning algorithms are used in organisations’ environments. Integrate ML specificities to awareness strategy and ensure all ML stakeholders are receiving it.(Not from the controls...)	no mapping
DASF 62	DASF 62: Implement network segmentation	Model Serving — Inference requests 9.13	Establish network and security policies to define and enforce egress and ingress rules on model endpoints and other essential resources, such as data storage and auxiliary API endpoints.	Databricks — Configuration	Co-managed	Private Preview as of November 2024. Ask your account team for more details.	Private Preview as of November 2024. Ask your account team for more details.	Private Preview as of November 2024. Ask your account team for more details.	DASF v 2.0	Platform and System Security	Operations and Platform 	Features available to implement control and manually verify	Traditional Control/Capability	M1030 Network Segmentation	no mapping	LLM01.4: Prompt injection LLM10.2: Model theft	no mapping	no mapping	A.8.22 Segregation of networks	AC-4:Information Flow Enforcement,  SC-3:Security Function Isolation,  SC-7:Boundary Protection,  SC-32:System Partitioning	no mapping	Ensure ML applications comply with protection policies and are integrated to security operations processes	no mapping
DASF 63	DASF 63: Update software	Platform 12.1	Patch and update software regularly to address existing and potential vulnerabilities throughout the AI lifecycle. In Databricks, automatic cluster updates ensure that all clusters within a workspace receive the latest OS images and security patches periodically. Account administrators can customize the maintenance window frequency, start date, and time.	Databricks — Out-of-the-box	Databricks Managed	https://docs.databricks.com/en/admin/clusters/automatic-cluster-update.html	https://learn.microsoft.com/en-us/azure/databricks/admin/clusters/automatic-cluster-update	N/A	DASF v 2.0	Platform and System Security	Operations and Platform 	Features available to implement control and manually verify	Traditional Control/Capability	no mapping	M1051 Update Software	LLM05.3, 4, 9: Supply Chain Vulnerabilities	ML06:2023 AI Supply Chain Attacks	no mapping	A.8.8 Management of technical vulnerabilities	SI-2:Flaw Remediation,  CM-6:Configuration Settings,  MA-3:Maintenance Tools	no mapping	Implement processes to maintain security levels of ML components over time. Check the vulnerabilities of the components used so that they have an appropriate security level. Ensure ML applications comply with protection policies and are integrated to security operations processes. Ensure ML projects follow the global process for integrating security into projects.	no mapping
DASF 64	DASF 64: Limit access from AI models and agents	Model Serving — Inference requests 9.12, Model Serving — Inference requests 9.13	Allow AI models and agents access to enterprise resources based on the principle of least privilege. In Unity Catalog, a "securable object" is any object that can be permissioned to a principal (e.g., user, service principal, or group) and is organized hierarchically. Treat AI as a principal and assign permissions accordingly.	Databricks — Configuration	Co-managed	https://docs.databricks.com/en/data-governance/unity-catalog/manage-privileges/privileges.html	https://learn.microsoft.com/en-us/azure/databricks/data-governance/unity-catalog/manage-privileges/privileges	https://docs.gcp.databricks.com/en/data-governance/unity-catalog/manage-privileges/privileges.html	DASF v 2.0	Access and Authentication	Catalog and governance,	GOV-16	Novel AI Control/Capability	no mapping	no mapping	LLM08: Excessive Agency	no mapping	no mapping	A.5.15 Access control	AC-2:Account Management,  AC-3:Access Enforcement,  AC-5:Separation of Duties,  AC-6:Least Privilege, CM-7:Least Functionality	Access to the AI system -> GenAI model least privilege	Ensure ML applications comply with security policies.	Article 5.4 Prohibited AI Practices Article 5.1 Prohibited AI Practices